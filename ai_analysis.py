# -*- coding: utf-8 -*-
import pandas as pd
import numpy as np
from openai import OpenAI


def get_market_analysis_stream(df, api_key, base_url, model_name, target_attr=None):
    """
    ç‹¬ç«‹æ¨¡å— V2.0ï¼šæ·±åº¦å¤šç»´æ•°æ®æŠ•å–‚ï¼Œç”Ÿæˆä¸“å®¶çº§æŠ¥å‘Šã€‚
    """
    try:
        # ==========================================
        # 1. æ•°æ®æ·±åº¦æŒ–æ˜ (Data Mining)
        # ==========================================

        # --- A. åŸºç¡€å¤§ç›˜ ---
        total_rev = df['æœˆé”€å”®é¢($)'].sum()
        avg_price = df['ä»·æ ¼($)'].mean()
        total_sales = df['æœˆé”€é‡'].sum()
        asin_count = len(df)

        # --- B. ç«äº‰ä¸å„æ–­ (CR5) ---
        top_brands = df.groupby('å“ç‰Œ')['æœˆé”€å”®é¢($)'].sum().sort_values(ascending=False).head(5)
        top5_share = (top_brands.sum() / total_rev * 100) if total_rev > 0 else 0
        brands_str = ", ".join([f"{b}({v / total_rev * 100:.1f}%)" for b, v in top_brands.items()])

        # --- C. å¸‚åœºæˆç†Ÿåº¦ä¸ç—›ç‚¹ (åŸºäºè¯„åˆ†) ---
        avg_rating = df['è¯„åˆ†'].mean() if 'è¯„åˆ†' in df.columns else 0
        avg_review_count = df['è¯„åˆ†æ•°'].mean() if 'è¯„åˆ†æ•°' in df.columns else 0
        # è®¡ç®—ä½åˆ†ç‡ (è¯„åˆ†ä½äº3.8çš„äº§å“å æ¯”)
        low_rating_ratio = len(df[df['è¯„åˆ†'] < 3.8]) / len(df) * 100 if 'è¯„åˆ†' in df.columns else 0

        # --- D. æ–°å“æ´»åŠ› (Barrier to Entry) ---
        # å‡è®¾ 'æ˜¯å¦æ–°å“' åˆ—å·²åœ¨ä¸»ç¨‹åºæ¸…æ´—å¥½ï¼Œå¦‚æœæ²¡æœ‰åˆ™å°è¯•è®¡ç®—
        if 'æ˜¯å¦æ–°å“' not in df.columns and 'ä¸Šæ¶å¤©æ•°' in df.columns:
            df['æ˜¯å¦æ–°å“'] = df['ä¸Šæ¶å¤©æ•°'].apply(lambda x: 'æ–°å“' if x <= 90 else 'è€å“')

        new_product_data = "æ— ä¸Šæ¶æ—¶é—´æ•°æ®"
        if 'æ˜¯å¦æ–°å“' in df.columns:
            new_products = df[df['æ˜¯å¦æ–°å“'].str.contains('æ–°å“')]
            new_share = (new_products['æœˆé”€å”®é¢($)'].sum() / total_rev * 100) if total_rev > 0 else 0
            new_count = len(new_products)
            new_product_data = f"æ–°å“(90å¤©å†…)å æ¯” {new_share:.1f}% (å…±{new_count}ä¸ª)ï¼Œæ–°å“å¹³å‡è¥æ”¶ ${new_products['æœˆé”€å”®é¢($)'].mean():,.0f}"

        # --- E. ä»·æ ¼å¸¦åˆ†å¸ƒ (Price Segmentation) ---
        # ç®€å•å°†ä»·æ ¼åˆ†ä¸ºï¼šä½ç«¯(<25%)ã€ä¸­ç«¯(25-75%)ã€é«˜ç«¯(>75%)
        p25, p75 = df['ä»·æ ¼($)'].quantile([0.25, 0.75])
        low_end = df[df['ä»·æ ¼($)'] <= p25]['æœˆé”€é‡'].sum()
        mid_end = df[(df['ä»·æ ¼($)'] > p25) & (df['ä»·æ ¼($)'] <= p75)]['æœˆé”€é‡'].sum()
        high_end = df[df['ä»·æ ¼($)'] > p75]['æœˆé”€é‡'].sum()
        price_structure = f"ä½ä»·åŒº(<${p25:.0f})é”€é‡å æ¯” {low_end / total_sales * 100:.0f}%, ä¸­ç«¯åŒºé”€é‡å æ¯” {mid_end / total_sales * 100:.0f}%, é«˜ç«¯åŒº(>${p75:.0f})é”€é‡å æ¯” {high_end / total_sales * 100:.0f}%"

        # --- F. å±æ€§åå¥½ (å¦‚æœæœ‰) ---
        attr_context = "ç”¨æˆ·æœªé€‰æ‹©ç‰¹å®šå±æ€§"
        if target_attr and target_attr in df.columns:
            top_attrs = df.groupby(target_attr)['æœˆé”€å”®é¢($)'].sum().sort_values(ascending=False).head(3)
            attr_list = ", ".join([f"{k}" for k in top_attrs.index])
            attr_context = f"åˆ†æå±æ€§ [{target_attr}]ï¼Œæœ€å¸é‡‘çš„ Top3 å˜ä½“ä¸º: {attr_list}"

        # ==========================================
        # 2. æ„å»ºä¸“å®¶çº§ Prompt
        # ==========================================
        system_prompt = """
        ä½ æ˜¯ä¸€ä½æ‹¥æœ‰ 20 å¹´ç»éªŒçš„äºšé©¬é€Šé¦–å¸­é€‰å“å®˜ (Chief Product Officer)ã€‚
        ä½ çš„é£æ ¼ï¼šé€»è¾‘ä¸¥å¯†ã€æ•°æ®é©±åŠ¨ã€ç›´å‡»ç—›ç‚¹ã€å•†ä¸šå—…è§‰æ•é”ã€‚
        ä½ ä¸ä»…ä¼šè¯»æ•°æ®ï¼Œè¿˜èƒ½é€šè¿‡æ•°æ®æ¨å¯¼å‡ºç”¨æˆ·ç”»åƒå’Œæ½œåœ¨çš„å•†ä¸šé£é™©ã€‚
        è¯·ä¸è¦å †ç Œè¾è—»ï¼Œç”¨æœ€å¹²ç»ƒçš„è¯­è¨€ç»™å‡ºå»ºè®®ã€‚
        """

        user_prompt = f"""
        è¯·åŸºäºä»¥ä¸‹å…¨ç»´åº¦å¸‚åœºæ•°æ®ï¼Œä¸ºæˆ‘è¾“å‡ºä¸€ä»½ã€Šæ·±åº¦é€‰å“å¯è¡Œæ€§æŠ¥å‘Šã€‹ï¼š

        ã€1. å¸‚åœºå¤§ç›˜ã€‘
        - æ€»æœˆæ”¶: ${total_rev:,.0f} | æ ·æœ¬æ•°: {asin_count}
        - å¹³å‡å®¢å•ä»·: ${avg_price:.2f}
        - ä»·æ ¼å¸¦é”€é‡ç»“æ„: {price_structure}

        ã€2. ç«äº‰å£å’ã€‘
        - å“ç‰Œå„æ–­åº¦ (CR5): {top5_share:.1f}% (Top5å“ç‰Œ: {brands_str})
        - è¯„è®ºé—¨æ§›: å¹³å‡è¯„è®ºæ•° {avg_review_count:.0f} ä¸ª
        - æ–°å“æœºä¼š: {new_product_data}

        ã€3. äº§å“è´¨é‡ä¸å±æ€§ã€‘
        - å¹³å‡è¯„åˆ†: {avg_rating:.2f} åˆ†
        - å·®è¯„çˆ†é›·ç‡ (<3.8åˆ†å æ¯”): {low_rating_ratio:.1f}% (å¦‚æœæ­¤å€¼é«˜ï¼Œè¯´æ˜æœ‰å·¨å¤§æ”¹è‰¯æœºä¼š)
        - {attr_context}

        ------------------------------------------
        è¯·æŒ‰ç…§ä»¥ä¸‹ Markdown ç»“æ„è¾“å‡ºåˆ†æï¼ˆå¿…é¡»åŒ…å« Emojiï¼‰ï¼š

        ### ğŸ¯ 1. æ ¸å¿ƒç»“è®º (Go / No-Go)
        ç”¨ä¸€å¥è¯åˆ¤å®šï¼šè¿™æ˜¯â€œè“æµ·æ¡é’±â€ã€â€œçº¢æµ·å®æ€â€è¿˜æ˜¯â€œå°è€Œç¾â€çš„å¸‚åœºï¼Ÿç»™å‡º 0-10 çš„æ¨èåˆ†ã€‚

        ### ğŸ‘¤ 2. ç”¨æˆ·ç”»åƒä¸ç—›ç‚¹æ¨æ¼”
        åŸºäºä»·æ ¼å¸¦å’Œè¯„åˆ†æ•°æ®ï¼Œæ¨æµ‹ä¹°å®¶æ˜¯ä»€ä¹ˆäººï¼Ÿä»–ä»¬æœ€åœ¨æ„ä»€ä¹ˆï¼Ÿ(å¦‚æœè¯„åˆ†ä½ï¼Œæ¨æµ‹ä»–ä»¬åœ¨è¿™ä¸ªå“ç±»ç»å¸¸æŠ±æ€¨ä»€ä¹ˆï¼Ÿ)

        ### ğŸ’° 3. é»„é‡‘åˆ‡å…¥ç‚¹ (Actionable Advice)
        - **å®šä»·ç­–ç•¥**ï¼šç»“åˆä»·æ ¼å¸¦ç»“æ„ï¼Œå»ºè®®æ–°å–å®¶å®šä»€ä¹ˆä»·ä½åˆ‡å…¥æœ€å®¹æ˜“å‡ºå•ï¼Ÿ
        - **å·®å¼‚åŒ–æ–¹å‘**ï¼šå¦‚æœå„æ–­åº¦é«˜ï¼Œå»ºè®®é¿å¼€ä»€ä¹ˆï¼Ÿå¦‚æœè¯„åˆ†ä½ï¼Œå»ºè®®æ”¹è‰¯ä»€ä¹ˆï¼Ÿ
        - **å±æ€§å»ºè®®**ï¼š{target_attr if target_attr else 'è§„æ ¼'} åº”è¯¥æ€ä¹ˆé€‰ï¼Ÿ

        ### âš ï¸ 4. æ­»äº¡é™·é˜±é¢„è­¦
        åŸºäºæ•°æ®ï¼ˆå¦‚æ–°å“å­˜æ´»ç‡ä½ã€å·¨å¤´å„æ–­ã€å·®è¯„ç‡é«˜ç­‰ï¼‰ï¼ŒæŒ‡å‡ºæœ€å¯èƒ½å¯¼è‡´äºæŸçš„å› ç´ ã€‚
        """

        # 3. å‘èµ·è¯·æ±‚
        client = OpenAI(api_key=api_key, base_url=base_url)
        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.6,  # ç¨å¾®é™ä½æ¸©åº¦ï¼Œè®©åˆ†ææ›´ç†æ€§
            stream=True
        )

        return response

    except Exception as e:
        return f"Error: AI åˆ†ææ¨¡å—è¿è¡Œå‡ºé”™ - {str(e)}"
